{
    "nbformat_minor": 0, 
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "version": "3.5.2", 
            "file_extension": ".py", 
            "name": "python", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "pygments_lexer": "ipython3"
        }, 
        "kernelspec": {
            "name": "python3", 
            "display_name": "Python 3.5 (Experimental) with Spark 1.6", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "<br><br>\n\n## Pr\u00e1ctica 6\n\n# Sistema de recomendaci\u00f3n en Spark\n\n\n### Luis de la Ossa\n\n\nEscuela Superior de Ingenier\u00eda Inform\u00e1tica de Albacete\n\n\n*Universidad de Castilla-La Mancha*\n\n---", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "### Introducci\u00f3n\n\nEl objetivo de esta pr\u00e1ctica es familiarizarse con la programaci\u00f3n y tratamiento de datos en _Apache Spark_. Para ello, se implementar\u00e1 un algoritmo de recomendaci\u00f3n basado en similaridad entre pel\u00edculas basado en las votaciones de los usuarios.\n\nHay que tener en cuenta que _Spark_ hace las operaciones cuando necesita los datos, y no antes. En ese caso, se reportan los errores, pero \u00e9stos pueden haberse producido en celdas anteriores aparentemente correctas. Con el fin de que pod\u00e1is comprobar cada paso, se ha a\u00f1adido un `collect()` comentado. \n\n__Nota__: El fin de este trabajo es esencialmente did\u00e1ctico. Por tanto, no todos los pasos est\u00e1n optimizados. ", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "### Lectura de datos\n\nPara esta pr\u00e1ctica, al igual que en la anterior, usaremos los archivos `u.data` y `u.items`. Para que Spark los lea es necesario proporcionar el acceso, que depender\u00e1 de si los tenemos almacenados en local, o trabajamos con el entorno DSX de IBM. \n\nLas siguientes celdas almacenan la ruta de acceso a cada uno de los archivos. En caso de trabajar en DSX, han de ser generadas desde el propio entorno. En el caso de `u.item` como _StringIO_, y en el caso de `u.data` como _SparkSession_.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "\nfrom io import StringIO\nimport requests\nimport json\nimport pandas as pd\n\n# @hidden_cell\n# This function accesses a file in your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef get_object_storage_file_with_credentials_74af1899931d4f94bb91ee5a4f761112(container, filename):\n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage.\"\"\"\n\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_225e6d7e906e9d9577669d9e9514b01252b88460','domain': {'id': '1777dedc403547c98be0dcc0821187a2'},\n            'password': 'w3NIn)2RB/FI-ylx'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2)\n    return StringIO(resp2.text)\n\n# Your data file was loaded into a StringIO object and you can process the data.\n# Please read the documentation of pandas to learn more about your possibilities to load your data.\n# pandas documentation: http://pandas.pydata.org/pandas-docs/stable/io.html\npath_movies = get_object_storage_file_with_credentials_74af1899931d4f94bb91ee5a4f761112('SistemaRecomendacion', 'u.item')\n", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": []
        }, 
        {
            "source": "\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_74af1899931d4f94bb91ee5a4f761112(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', 'e67e4544bd794bb7bf3a337a94365c28')\n    hconf.set(prefix + '.username', '796eadbf96a44e40a20ada8abfb937da')\n    hconf.set(prefix + '.password', 'w3NIn)2RB/FI-ylx')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_74af1899931d4f94bb91ee5a4f761112(name)\n\n# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/1.6.0/api/python/pyspark.sql.html#pyspark.sql.SQLContext\n# The SQLContext object is already initalized for you.\n# The following variable contains the path to your file on your Object Storage.\npath_ratings = \"swift://SistemaRecomendacion.\" + name + \"/u.data\"\n", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "A continuaci\u00f3n, y puesto que la lista de pel\u00edculas solamente se utilizar\u00e1 en modo local, la almacenaremos en un _DataFrame_ Pandas.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "import pandas as pd\n\nnames_mv = ['id', 'title', 'release', 'video', 'IMDb URL',\n            'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', \n            'Documentary', 'Drama', 'Fantasy',' Film-Noir', 'Horror', 'Musical', 'Mystery', \n            'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n\ndf_movies = pd.read_csv(path_movies, sep='|', encoding='iso-8859-1', names=names_mv)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "Los datos relativos a las votaciones los almacenaremos en un RDD.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "dataRDD = sc.textFile(path_ratings)", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n### Algoritmo de recomendaci\u00f3n basado en similaridad entre pel\u00edculas.\n\nEn esta parte implementaremos un algoritmo basado en similaridad entre pel\u00edculas. Posteriormente, se obtendr\u00e1n las m\u00e1s similares a una dada. \n\nLa t\u00e9cnica es parecida a la vista en clase. Dadas dos pel\u00edculas, su similaridad se obtiene a partir de las valoraciones que han hecho los usuarios __que hayan visto ambas__. Hemos de pensar (aunque habr\u00eda que cambiar algunas cosas en el programa si en realidad fuera as\u00ed) que el n\u00famero de usuarios es muy grande. ", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "#### Ejercicio 1.\n\nEn primer lugar, vamos a convertir el RDD de texto en un RDD con tuplas `(user_id, (movie_id, rating))`, denominado `ratingsRDD`, en el que `user_id` y `movie_id` son enteros, y `rating`es float. Utilizar la funci\u00f3n `map`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "ratingsRDD = dataRDD.map(lambda x: x.split('\\t'))\nratingsRDD = ratingsRDD.map(lambda x: tuple([int(x[0]),tuple([int(x[1]),float(x[2])])]))\n\nprint(ratingsRDD.collect()[:3])\n#[(196, (242, 3.0)), (186, (302, 3.0)), (22, (377, 1.0))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "[(196, (242, 3.0)), (186, (302, 3.0)), (22, (377, 1.0))]\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\nDe cara a dise\u00f1ar el algoritmo, el principal factor a tener en cuenta es que se van a comparar pares de pel\u00edculas, y para ello solamente se consider\u00e1n las valoraciones de usuarios que hayan visto ambas. Por ejemplo, si dos pel\u00edculas `movie_A`y `movie_B` han sido valoradas por cinco usuarios\n\n$$\nmovie\\_A = [ 0, 2, 4, 0, 1] \\quad movie\\_B = [1 ,3, 5, 0, 0], \n$$\n\nsolamente se se utilizar\u00e1n las valoraciones de los usuarios 2 y 3, que han visto ambas pel\u00edculas. Visto de otro modo, m\u00e1s aproximado a c\u00f3mo se proceder\u00e1 aqu\u00ed, el usuario 1, por ejemplo, no se tendr\u00e1 en cuenta para calcular la distancia entre la pel\u00edcula `movie_A` y ninguna otra. Por ello en primer lugar se van a generar los pares de pel\u00edculas vistas por un mismo usuario. \n\nEn el apartado anterior se han generado tuplas del tipo `(user_id, (movie_id, rating))`. Si se hace un _inner join_ de `ratingsRDD` con \u00e9l mismo, cada entrada del primer RDD se unir\u00e1 con las entradas del segundo RDD con las que comparta clave (`user_id`), generando tuplas del tipo:  `(user_id, ((movie_id1, rating1), (movie_id2, rating2))`.\n\n\n\n#### Ejercicio 2. \n\nHacer un join del RDD `ratingsRDD` y almacenar el resultado en otro denominado `join_ratingsRDD`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "join_ratingsRDD = ratingsRDD.join(ratingsRDD)\n\njoin_ratingsRDD.collect()[:3]\n#[(512, ((265, 4.0), (265, 4.0))),\n# (512, ((265, 4.0), (23, 4.0))),\n# (512, ((265, 4.0), (1, 4.0)))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 6, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[(512, ((265, 4.0), (265, 4.0))),\n (512, ((265, 4.0), (23, 4.0))),\n (512, ((265, 4.0), (1, 4.0)))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 6
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\nEn este punto, cada par de pel\u00edculas vistas por un usuario aparece dos veces en `join_ratingsRDD`, ya que aparecer\u00edan en orden inverso. Es decir, por cada entrada `(user_id, ((movie_id1, rating1), (movie_id2, rating2))` tendr\u00edamos otra como `(user_id, ((movie_id2, rating2), (movie_id1, rating1))`. Para eliminar los duplicados, vamos a dejar solamente aquellas entradas en las que el \u00edndice de la primera pel\u00edcula `movie_id1`, sea menor que el de la segunda `movie_id2`.\n\n#### Ejercicio 3.\n\nImplementar una funci\u00f3n denominada `filter_duplicates` que reciba una tupla del tipo `((movie_id1, rating1), (movie_id2, rating2))` y devuelva `True` cuando `movie_id1 < movie_id2`, y `False` en caso contrario. ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "def filter_duplicates(ratings):\n    return ratings[0][0] < ratings[1][0]", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": 7, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\n#### Ejercicio 4.\n\nUtilizar la funci\u00f3n anterior para eliminar los duplicados de `join_ratingsRDD`, mediante `filter`. \n\n__Nota__: Hay que tener en cuenta que cada entrada de `join_ratingsRDD` es una tupla `(user_id, ((movie_id1, rating1), (movie_id2, rating2))`. Por tanto, a la funci\u00f3n `filter_duplicates` hay que pasarle el segundo de los componentes de la tupla, ya que el primero es `user_id`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "join_ratingsRDD = join_ratingsRDD.filter(lambda x: filter_duplicates(x[1]))\n\njoin_ratingsRDD.collect()[:3]\n#[(512, ((265, 4.0), (318, 5.0))),\n# (512, ((265, 4.0), (1459, 4.0))),\n# (512, ((265, 4.0), (313, 3.0)))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 8, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[(512, ((265, 4.0), (318, 5.0))),\n (512, ((265, 4.0), (1459, 4.0))),\n (512, ((265, 4.0), (313, 3.0)))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 8
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\nEn este punto, se dispone de entradas `(user_id, ((movie_id1, rating1), (movie_id2, rating2))`. De cara a computar la similaridad entre pel\u00edculas, se incluir\u00e1n en los vectores correspondientes a las pel\u00edculas `movie_id1` y `movie_id2` las valoraciones correspondientes al usuario `user_id`.  Sin embargo, el usuario en si es irrelevante. Por otra parte, de cara a hacer los c\u00e1lculos de similaridad, lo importante es buscar los pares de pel\u00edculas.\n\n#### Ejercicio 5.\n\nTransformar el RDD `join_ratingsRDD` en el que las entradas son del tipo,  `(user_id, ((movie_id1, rating1), (movie_id2, rating2))`, en un RDD pareado denominado `movie_pairsRDD`, en el que las entradas sean de tipo `((movie_id1, movie_id2),(rating1, rating2))`. Utilizar la funci\u00f3n `map`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "movie_pairsRDD = join_ratingsRDD.map(lambda x: tuple([tuple([x[1][0][0],x[1][1][0]]),tuple([x[1][0][1],x[1][1][1]])]))\n\nmovie_pairsRDD.collect()[:3]\n#[((265, 318), (4.0, 5.0)), ((265, 1459), (4.0, 4.0)), ((265, 313), (4.0, 3.0))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[((265, 318), (4.0, 5.0)), ((265, 1459), (4.0, 4.0)), ((265, 313), (4.0, 3.0))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 9
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "Para cada poder calcular la similaridad entre un par de pel\u00edculas, han de obtenerse las valoraciones echas por cada usuario que haya visto ambas, es decir, buscar todas las tuplas `(movie_id1, movie_id2)`, y agrupar los pares `(rating1, rating2)` de cada una de ellas.\n\n---\n\n#### Ejercicio 6.\n\nAgrupar las valoraciones existentes en el RDD `movie_pairsRDD` para cada par `(movie_id1, movie_id2)`, generando un RDD pareado denominado `movie_pairs_ratingsRDD` del tipo `(movie_id1, movie_id2): [(rating1, rating2), (rating1, rating2), ...] `.  Utilizar para ello `groupByKey()`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "movie_pairs_ratingsRDD = movie_pairsRDD.groupByKey()\n\nmovie_pairs_ratingsRDD.collectAsMap()[(366,854)].data   # Obtiene los ratings correspondientes a la entrada (366,854) (tres en total).\n#[(3.0, 4.0), (2.0, 1.0), (3.0, 1.0)]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 10, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[(3.0, 1.0), (2.0, 1.0), (3.0, 4.0)]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 10
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\n### C\u00e1lculo de la distancia coseno. Opci\u00f3n 1.\n\nA continuaci\u00f3n, y aunque en este contexto no es necesario, vamos a transformar la lista de valoraciones para cada par de pel\u00edculas, que tenemos almacenada con formato  `[(3.0, 4.0), (2.0, 1.0), (3.0, 1.0)]` a un formato en el que la lista de valoraciones de cada pel\u00edcula se represente como una dos tupla de tipo `((3.0, 2.0, 3.0), (4.0, 1.0, 1.0))`, que podr\u00e1n ser convertidas posteriormente en vectores `Numpy` para el c\u00e1lculo de la similaridad. El resultado lo guardaremos en la variable `movie_pairs_ratings2VRDD`.\n\n__Nota__: Este paso no es estrictamente necesario. Incluso en este caso puede compensar calcular directamente la distancia coseno con una versi\u00f3n iterativa de la misma. Pero en otras situaciones, s\u00ed que puede serlo.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "movie_pairs_ratings2VRDD = movie_pairs_ratingsRDD.mapValues(lambda ratings: list(zip(*ratings.data)))\nmovie_pairs_ratingsRDD.collectAsMap()[(197, 1097)]\n#[(4.0, 3.0, 5.0, 3.0, 4.0, 2.0, 5.0), (5.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0)]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 11, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<pyspark.resultiterable.ResultIterable at 0x7ff9010599b0>"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 11
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "Ahora podemos definir la funci\u00f3n similaridad coseno, de modo que reciba una lista con dos tuplas (los dos vectores), los transforme en vectores, y devuelva sus distancias, as\u00ed como el n\u00famero de elementos que tienen.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "import numpy as np\n\ndef cos_sim_v(ratings):\n    # Convierte a arrays\n    ratings_movie_0 = np.asarray(ratings[0])\n    ratings_movie_1 = np.asarray(ratings[1])\n    # Calcula la similaridad\n    num = ratings_movie_0.dot(ratings_movie_1)\n    den = np.sqrt(ratings_movie_0.dot(ratings_movie_0))*np.sqrt(ratings_movie_1.dot(ratings_movie_1))\n    return num/den, len(ratings[0])\n\ncos_sim_v([(4.0, 3.0, 5.0, 3.0, 4.0, 2.0, 5.0), (5.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0)])\n#(0.97587290935995985, 7)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 12, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "(0.97587290935995985, 7)"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 12
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Ejercicio 7\n\nCalcular la similaridad coseno para cada par de pel\u00edculas de almacenadas en `movie_pairs_ratings2VRDD` y almacenar el resultado en `movie_pair_similaritiesRDD`. Hacer persistente el resultado llamando al m\u00e9todo `cache()`. El resultado incluye la similaridad, as\u00ed como el n\u00famero de personas que han valorado ambas pel\u00edculas (es lo que devuelve la funci\u00f3n `cos_sim_v`).", 
            "cell_type": "markdown"
        }, 
        {
            "source": "movie_pair_similaritiesRDD = movie_pairs_ratings2VRDD.mapValues(lambda x: cos_sim_v(x)).cache()\n\nmovie_pair_similaritiesRDD.collect()[:3]\n#[((197, 1097), (0.97587290935995985, 7)),\n# ((42, 364), (0.90934865603988357, 18)),\n# ((273, 617), (0.96529535990071047, 7))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 13, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[((197, 1097), (0.97587290935995985, 7)),\n ((773, 1409), (1.0, 1)),\n ((273, 617), (0.96529535990071047, 7))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 13
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\n### C\u00e1lculo de la distancia coseno. Opci\u00f3n 2.\n\nEn el caso de que los vectores de valoraciones comunes para las pel\u00edculas, almacenados en `movie_pairs_ratingsRDD` con formato `[(3.0, 4.0), (2.0, 1.0), (3.0, 1.0)]` sean excesivamente largos, puede no ser adecuada la vectorizaci\u00f3n. En ese caso, puede calcularse directamente la similaridad coseno con un algoritmo tradicional.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from math import sqrt\n\ndef cos_sim(ratings):\n    num_ratings = 0\n    sum_1 = sum_2= sum_12 = 0    \n    for rating1, rating2 in ratings:\n        sum_1 += rating1 * rating1\n        sum_2 += rating2 * rating2\n        sum_12 += rating1 * rating2\n        num_ratings += 1\n    \n    num = sum_12\n    den = sqrt(sum_1) * sqrt(sum_2)\n\n    return num / float(den), num_ratings\n\ncos_sim([(3.0, 4.0), (2.0, 1.0), (3.0, 1.0)])\n#(0.8542821429703302, 3)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 14, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "(0.8542821429703302, 3)"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 14
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Ejercicio 8\n\nCalcular la similaridad coseno (ahora con el m\u00e9todo `cos_sim`) para cada par de pel\u00edculas de almacenadas en `movie_pairs_ratingsRDD` (el original que contiene 2-tuplas) y almacenar el resultado en `movie_pair_similaritiesRDD`. Hacer persistente el resultado llamando al m\u00e9todo `cache()`. El resultado incluye la similaridad, as\u00ed como el n\u00famero de personas que han valorado ambas pel\u00edculas (es lo que devuelve la funci\u00f3n `cos_sim`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "movie_pair_similaritiesRDD = movie_pairs_ratingsRDD.mapValues(lambda x: cos_sim(x)).cache()\n\nmovie_pair_similaritiesRDD.collect()[:3]\n#[((197, 1097), (0.9758729093599599, 7)),\n# ((773, 1409), (1.0, 1)),\n# ((273, 617), (0.9652953599007105, 7))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 15, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[((197, 1097), (0.9758729093599599, 7)),\n ((42, 364), (0.9093486560398836, 18)),\n ((273, 617), (0.9652953599007105, 7))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 15
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "## Pel\u00edculas similares a una dada.\n\nA continuaci\u00f3n, se van a generar las pel\u00edculas similares a una dada (la 10). Solamente se considerar\u00e1n aquellas cuya similaridad est\u00e9 por encima de 0.97 y, adem\u00e1s, hayan sido votadas por al menos 20 personas que votaron la pel\u00edcula original. ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "min_sim = 0.97\nmin_common = 20\nmovie_id = 10", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": 16, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Ejercicio 9\n\nFiltrar los resultados de inter\u00e9s. Es decir, lo que que cumplan los criterios descritos anteriormente y almacenarlos en un RDD denominado `similar_moviesRDD`, es decir, que la primera o la segunda pel\u00edcula sea `movie_id`, que la similaridad est\u00e9 por encima de 0.97, y que el n\u00famero de personas que han visto ambas sea al menos 50.  Utilizar la funci\u00f3n `filter`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "similar_moviesRDD = movie_pair_similaritiesRDD.filter(lambda x: (x[0][0] == movie_id or x[0][1] == movie_id) and x[1][0] > min_sim and x[1][1] > min_common)\n\nsimilar_moviesRDD.collect()[:3]\n#[((10, 792), (0.978909167336141, 24)),\n# ((10, 528), (0.9748821327187926, 25)),\n# ((10, 387), (0.9762910550634251, 21))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 17, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[((10, 792), (0.978909167336141, 24)),\n ((10, 528), (0.9748821327187926, 25)),\n ((10, 527), (0.9723706468984957, 29))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 17
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\n#### Ejercicio 10\n\nOrdenar los resultados de `similar_moviesRDD` por similaridad. Utilizar para ello `sortBy`. Devolver los 10 primeros elementos del RDD resultante con `take` y almacenarlos en la lista `results`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "results = similar_moviesRDD.sortBy(lambda x: x[1][0]).take(10)[::-1]\n\nresults[:3]\n#[((10, 558), (0.9885451117519884, 21)),\n# ((10, 474), (0.9801007017199401, 34)),\n# ((10, 223), (0.9796226612103792, 27))]", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 18, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[((10, 792), (0.978909167336141, 24)),\n ((10, 709), (0.9788941627901632, 22)),\n ((10, 387), (0.9762910550634251, 21))]"
                    }, 
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "execution_count": 18
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Muestra los resultados\n\nA continuaci\u00f3n, se muestran los resultados obtenidos.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "for result in results:\n    print(result)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 19, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "((10, 792), (0.978909167336141, 24))\n((10, 709), (0.9788941627901632, 22))\n((10, 387), (0.9762910550634251, 21))\n((10, 59), (0.9749784735609486, 21))\n((10, 528), (0.9748821327187926, 25))\n((10, 527), (0.9723706468984957, 29))\n((10, 169), (0.9718073257951023, 22))\n((10, 190), (0.9714818546315672, 39))\n((10, 429), (0.9708688309717662, 21))\n((10, 89), (0.9701678111320445, 45))\n"
                }
            ]
        }, 
        {
            "source": "print(\"Las 10 pel\u00edculas m\u00e1s parecidas a \" + df_movies.iloc[movie_id]['title']+\"\\n\\n\")\n\nfor result in results:\n    (pair, sim) = result\n    sim_movie_id = pair[1]\n    print(df_movies.iloc[sim_movie_id]['title'] + \"\\n\\t\\tSimilaridad: %.2f \\t Votada en com\u00fan:%d\\n\" % (sim[0],sim[1]))", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 20, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Las 10 pel\u00edculas m\u00e1s parecidas a Seven (Se7en) (1995)\n\n\nCrooklyn (1994)\n\t\tSimilaridad: 0.98 \t Votada en com\u00fan:24\n\nBetter Off Dead... (1985)\n\t\tSimilaridad: 0.98 \t Votada en com\u00fan:22\n\nBeverly Hills Cop III (1994)\n\t\tSimilaridad: 0.98 \t Votada en com\u00fan:21\n\nThree Colors: Blue (1993)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:21\n\nMy Life as a Dog (Mitt liv som hund) (1985)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:25\n\nKilling Fields, The (1984)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:29\n\nCinema Paradiso (1988)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:22\n\nAmadeus (1984)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:39\n\nDuck Soup (1933)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:21\n\nSo I Married an Axe Murderer (1993)\n\t\tSimilaridad: 0.97 \t Votada en com\u00fan:45\n\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n## Librer\u00eda MLib: ALS (Alternative Least Squares)\n\nLa librer\u00eda _MLib_ contiene algoritmos de aprendizaje autom\u00e1ticos implementados para ejecutarse sobre la plataforma _Spark_. \n\nComo ejemplo, vamos entrenar un sistema de recomendaci\u00f3n basado en _Alternative Least Squares_. Como se vio en el tema, este algoritmo optimiza tanto los par\u00e1metros que caracterizan las pel\u00edculas ($X$) como los que caracterizan a los usuarios $\\theta$. Es decir, hace una factorizaci\u00f3n de matrices.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from pyspark.mllib.recommendation import ALS, Rating", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": 21, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Ejercicio 11.\n\nTransformar los datos del RDD `dataRDD` en otro RDD de objetos `Rating`. Cada uno de ellos se crea como `Rating(user_id, movie_id,rating)`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "ratingsRDD = dataRDD.map(lambda x: x.split('\\t'))\nratingsRDD = ratingsRDD.map(lambda x: Rating(x[0],x[1],x[2]))", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 22, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Ejercicio 12.\n\nEntrenar el modelo, con los par\u00e1metros proporcionados (mirar documentaci\u00f3n). ", 
            "cell_type": "markdown"
        }, 
        {
            "source": "rank = 10\nn_iterations = 6\nmodel = ALS.train(ratingsRDD, rank, iterations=n_iterations)", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 23, 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "\n---\n\n#### Ejercicio 13. \n\nObtener las valoraciones para el usuario 20 y almacenarlas en `user_ratingsRDD`.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "user_id = 20\nprint(\"\\nValoraciones para el usuario \" + str(user_id) + \": \\n\")\n\n# Filtra por usuario\ndataRDD2 = dataRDD.map(lambda x: x.split('\\t'))\nuser_ratingsRDD = dataRDD2.filter(lambda x: int(x[0]) == user_id)\n\nprint(\"El usuario ha votado %d pel\u00edculas \\n\\n\" %(user_ratingsRDD.count()))\n\n# Las imprime\nfor rating in user_ratingsRDD.collect():\n    print(df_movies.iloc[int(rating[1])]['title']+\": \" + str(rating[2]))", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 24, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "\nValoraciones para el usuario 20: \n\nEl usuario ha votado 48 pel\u00edculas \n\n\nEvita (1996): 1\nThis Is Spinal Tap (1984): 2\nUsual Suspects, The (1995): 2\nGood, The Bad and The Ugly, The (1966): 2\nMaya Lin: A Strong Clear Vision (1994): 4\nGodfather: Part II, The (1974): 3\nPrincess Bride, The (1987): 3\nConan the Barbarian (1981): 4\nTerminator, The (1984): 3\nThinner (1996): 3\nGoldenEye (1995): 3\nFour Weddings and a Funeral (1994): 1\nCrow: City of Angels, The (1996): 4\nBig Squeeze, The (1996): 3\nFirst Kid (1996): 1\nTerminator 2: Judgment Day (1991): 3\nCable Guy, The (1996): 3\nPillow Book, The (1995): 4\nWolf (1994): 4\nLawnmower Man, The (1992): 2\nSnow White and the Seven Dwarfs (1937): 3\nSleepless in Seattle (1993): 5\nCat on a Hot Tin Roof (1958): 3\nWild Bunch, The (1969): 4\nWhole Wide World, The (1996): 1\nChildren of the Corn: The Gathering (1996): 2\nGoodFellas (1990): 4\nAladdin (1992): 2\nIf Lucy Fell (1996): 1\nParadise Road (1997): 4\nM*A*S*H (1970): 4\nBrazil (1985): 4\nMrs. Winterbourne (1996): 2\nSpawn (1997): 1\nSleeper (1973): 3\nJude (1996): 5\nTales From the Crypt Presents: Demon Knight (1995): 3\nSense and Sensibility (1995): 4\nBringing Up Baby (1938): 5\nDie Hard (1988): 3\nMicrocosmos: Le peuple de l'herbe (1996): 4\nLost Highway (1997): 4\nTaxi Driver (1976): 5\nLegends of the Fall (1994): 3\nSmilla's Sense of Snow (1997): 4\nMuch Ado About Nothing (1993): 4\nPatton (1970): 3\nFrench Twist (Gazon maudit) (1995): 4\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "---\n\n#### Ejercicio 14.\n\nObtener e imprimir las 10 mejores recomendaciones para el usuario (a partir del objeto `model` creado anteriormente.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "print(\"\\nMejores 10 recomendaciones \\n \")\n\nrecommendations = model.recommendProducts(user_ratingsRDD).take(10)\n\nfor recommendation in recommendations:\n    print(df_movies.iloc[int(recommendation[1])]['title'] + \"\\t Score \" + str(recommendation[2]))", 
            "metadata": {
                "collapsed": false
            }, 
            "cell_type": "code", 
            "execution_count": 97, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "\nMejores 10 recomendaciones \n \n"
                }, 
                {
                    "output_type": "error", 
                    "ename": "TypeError", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-97-f53109659a37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nMejores 10 recomendaciones \\n \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrecommendations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommendProducts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ratingsRDD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrecommendation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mTypeError\u001b[0m: recommendProducts() missing 1 required positional argument: 'num'"
                    ], 
                    "evalue": "recommendProducts() missing 1 required positional argument: 'num'"
                }
            ]
        }, 
        {
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": []
        }
    ]
}